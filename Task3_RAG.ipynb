{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Deep learning framework for GPU-accelerated tensor operations\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  # Hugging Face tools for loading and configuring language models\n",
    "from sentence_transformers import SentenceTransformer  # For generating text embeddings/vectors\n",
    "import faiss  # Fast similarity search and clustering of dense vectors\n",
    "import numpy as np  # Numerical computing library for array operations\n",
    "from typing import List, Dict  # Type hints for better code documentation\n",
    "from scape import PaperScraper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.25s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model for generating text embeddings\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')  # Load the BGE large model for high quality embeddings\n",
    "embedding_model.to('cuda')  # Move embedding model to GPU for faster inference\n",
    "\n",
    "# Configure quantization for efficient GPU usage\n",
    "bnb_config = BitsAndBytesConfig(  # Configure 4-bit quantization settings\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization for reduced memory usage\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Use normalized float4 quantization for better accuracy\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # Use float16 for compute to balance speed and precision\n",
    "    bnb_4bit_use_double_quant=True  # Enable double quantization for additional memory savings\n",
    ")\n",
    "\n",
    "# Initialize LLM and tokenizer\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"  # Specify the Mistral model to use\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)  # Load tokenizer for converting text to tokens\n",
    "model = AutoModelForCausalLM.from_pretrained(  # Load the language model\n",
    "    model_name,  # Use the specified Mistral model\n",
    "    quantization_config=bnb_config,  # Apply the quantization settings\n",
    "    torch_dtype=torch.float16,  # Use float16 for model weights\n",
    "    device_map=\"auto\",  # Automatically distribute model across available GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without retrieval (standard Transformer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAssistant:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        \"\"\"\n",
    "        Initialize the standard Transformer model for direct QA.\n",
    "        \"\"\"\n",
    "        self.model = model  # Pre-trained language model (e.g., GPT, Llama)\n",
    "        self.tokenizer = tokenizer  # Tokenizer for the model\n",
    "\n",
    "    def answer_question(self, question: str):\n",
    "        \"\"\"\n",
    "        Answer a question using the transformer model WITHOUT retrieval.\n",
    "        \"\"\"\n",
    "        # Construct the prompt (no retrieval context added)\n",
    "        prompt = f\"Answer the following question:\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "\n",
    "        # Tokenize the input question\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=1024  # Limit token length\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        # Generate response using the transformer model\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,  # Limit response length\n",
    "            temperature=0.7,  # Add some randomness\n",
    "            num_return_sequences=1,  # Generate one response\n",
    "            do_sample=True  # Use sampling for diversity\n",
    "        )\n",
    "\n",
    "        # Decode the generated output\n",
    "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return answer.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: What are the main challenges in using CRISPR for cancer therapy?\n",
      "\n",
      "A: Answer the following question:\n",
      "\n",
      "Question: What are the main challenges in using CRISPR for cancer therapy?\n",
      "\n",
      "Answer:\n",
      "\n",
      "CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) is a powerful gene editing tool that has shown promise for the treatment of various diseases, including cancer. However, there are several challenges associated with using CRISPR for cancer therapy, which include:\n",
      "\n",
      "1. Off-target effects: One of the major challenges in using CRISPR for cancer therapy is the possibility of off-target effects, which occur when the gene editing tool cuts DNA at unintended sites. This can lead to unintended consequences and potentially harmful side effects.\n",
      "2. Tumor heterogeneity: Cancer tumors are complex and heterogeneous, meaning they contain a mixture of different types of cells. This can make it difficult to target specific cancer cells with CRISPR, as the tool may not be able to distinguish between cancer cells and healthy cells.\n",
      "3. Delivery: Delivering CRISPR to cancer cells can be a challenge, as tumors often have a thick and dense outer layer that can impede the delivery of the gene editing tool. Additionally, cancer cells may be in a state of heightened immune activity, which can make it more difficult to deliver CRISPR without triggering an\n"
     ]
    }
   ],
   "source": [
    "# Initialize the assistant\n",
    "assistant = ResearchAssistant(model,    tokenizer  )\n",
    "\n",
    "\n",
    "# Ask questions\n",
    "questions = [\n",
    "    \"What are the main challenges in using CRISPR for cancer therapy?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"\\nA: {assistant.answer_question(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple document retriever using ChromaDB, indexing a small collection of scientific papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Paper IDs: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "# Initialize ChromaDB client\n",
    "chroma_client = chromadb.PersistentClient(path=\"chromadb_store\")  # Update path if necessary\n",
    "\n",
    "# Load collection where papers are stored\n",
    "collection = chroma_client.get_or_create_collection(name=\"research_papers\")\n",
    "\n",
    "# Define a search query\n",
    "query_text = \"Graph Neural Networks for biological applications\"\n",
    "\n",
    "# Convert query to embedding (use your embedding model)\n",
    "# Example: If using OpenAI embeddings, use openai.Embedding.create()\n",
    "query_embedding = embedding_model.encode(query_text)  # Replace with actual embedding function\n",
    "\n",
    "# Perform similarity search\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=10  # Number of relevant papers to retrieve\n",
    ")\n",
    "\n",
    "# Extract paper IDs\n",
    "paper_ids = results['ids'][0]  # ChromaDB returns a list of lists\n",
    "print(\"Relevant Paper IDs:\", paper_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With retrieval (RAG-based Transformer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 (text-based search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prart\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "class ResearchAssistantBM25:\n",
    "    def __init__(self):\n",
    "        self.scraper = PaperScraper()  # Paper retrieval module\n",
    "        self.tokenizer = tokenizer  # LLM tokenizer\n",
    "        self.model = model  # LLM model for answering questions\n",
    "        \n",
    "        self.paper_texts = []  # Store paper texts\n",
    "        self.paper_metadata = []  # Store metadata (title, authors, etc)\n",
    "        self.bm25 = None  # BM25 index (to be built)\n",
    "\n",
    "    def search_papers(self, query: str, max_results: int = 10):\n",
    "        \"\"\"Search and download papers for the given query\"\"\"\n",
    "        print(f\"Searching for papers about: {query}\")\n",
    "\n",
    "        pmids = self.scraper.search_pubmed(query, max_results)\n",
    "        papers = self.scraper.fetch_pubmed_details(pmids)\n",
    "\n",
    "        for paper in papers:\n",
    "            if pdf_url := paper.get('full_text_link'):\n",
    "                try:\n",
    "                    pdf_path = self.scraper.download_pdf(pdf_url, f\"temp_{paper['pubmed_id']}.pdf\")\n",
    "                    text = self.scraper.extract_text_from_pdf(pdf_path)\n",
    "\n",
    "                    self.paper_texts.append(text)\n",
    "                    self.paper_metadata.append(paper)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing paper {paper['pubmed_id']}: {e}\")\n",
    "\n",
    "        self._build_bm25_index()\n",
    "        print(f\"Successfully processed {len(self.paper_texts)} papers\")\n",
    "\n",
    "    def _build_bm25_index(self):\n",
    "        \"\"\"Build BM25 index from paper texts\"\"\"\n",
    "        self.chunks = []\n",
    "        self.chunk_metadata = []\n",
    "\n",
    "        for text, metadata in zip(self.paper_texts, self.paper_metadata):\n",
    "            paragraphs = text.split('\\n\\n')\n",
    "            for i in range(0, len(paragraphs), 2):  # Overlapping chunks\n",
    "                chunk = ' '.join(paragraphs[i:i+2])\n",
    "                if len(chunk.split()) > 30:\n",
    "                    self.chunks.append(chunk)\n",
    "                    self.chunk_metadata.append(metadata)\n",
    "\n",
    "        # Tokenize each chunk for BM25\n",
    "        tokenized_chunks = [nltk.word_tokenize(chunk.lower()) for chunk in self.chunks]\n",
    "\n",
    "        # Initialize BM25 Index\n",
    "        self.bm25 = BM25Okapi(tokenized_chunks)\n",
    "\n",
    "    def answer_question(self, question: str, k: int = 5):\n",
    "        \"\"\"Retrieve relevant papers using BM25 and answer with LLM\"\"\"\n",
    "        query_tokens = nltk.word_tokenize(question.lower())\n",
    "\n",
    "        # Get top-k ranked documents\n",
    "        scores = self.bm25.get_scores(query_tokens)\n",
    "        ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
    "\n",
    "        # Build context from retrieved documents\n",
    "        context = \"\"\n",
    "        used_papers = set()\n",
    "        total_tokens = 0\n",
    "        max_tokens = 2048\n",
    "\n",
    "        for idx in ranked_indices:\n",
    "            chunk = self.chunks[idx]\n",
    "            metadata = self.chunk_metadata[idx]\n",
    "            paper_id = metadata[\"pubmed_id\"]\n",
    "\n",
    "            if paper_id not in used_papers:\n",
    "                chunk_tokens = len(self.tokenizer.encode(chunk))\n",
    "                if total_tokens + chunk_tokens > max_tokens:\n",
    "                    break\n",
    "\n",
    "                used_papers.add(paper_id)\n",
    "                context += f\"\\nFrom paper '{metadata['title']}':\\n{chunk}\\n\"\n",
    "                total_tokens += chunk_tokens\n",
    "\n",
    "        # Construct final LLM prompt\n",
    "        prompt = f\"\"\"Answer based on these excerpts. Include citations.\n",
    "\n",
    "        Excerpts: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer: \"\"\"\n",
    "\n",
    "        # Generate answer using LLM\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=2048\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.7,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True\n",
    "        )\n",
    "        input_length = inputs[\"input_ids\"].shape[1]  # Number of tokens in input prompt\n",
    "        output_token_length = outputs.shape[1] - input_length  # Total generated tokens excluding input\n",
    "        # Extract answer\n",
    "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return answer.split(\"Answer: \")[-1].strip(),output_token_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scape:Searching PubMed for : latest developments in CRISPR gene editing cancer therapy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for papers about: latest developments in CRISPR gene editing cancer therapy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scape:Found 28 results\n",
      "INFO:scape:Fetching details for 28 papers...\n",
      "INFO:scape:Successfully processed PMID 37356052\n",
      "INFO:scape:Successfully processed PMID 36610813\n",
      "INFO:scape:Successfully processed PMID 36272261\n",
      "INFO:scape:Successfully processed PMID 35337340\n",
      "INFO:scape:Successfully processed PMID 39708520\n",
      "INFO:scape:Successfully processed PMID 38050977\n",
      "INFO:scape:Successfully processed PMID 34411650\n",
      "INFO:scape:Successfully processed PMID 31739699\n",
      "INFO:scape:Successfully processed PMID 36560658\n",
      "INFO:scape:Successfully processed PMID 33003295\n",
      "INFO:scape:Successfully processed PMID 39317648\n",
      "INFO:scape:Successfully processed PMID 35547744\n",
      "INFO:scape:Successfully processed PMID 39292321\n",
      "INFO:scape:Successfully processed PMID 35999480\n",
      "INFO:scape:Successfully processed PMID 32264803\n",
      "INFO:scape:Successfully processed PMID 38041049\n",
      "INFO:scape:Successfully processed PMID 36139078\n",
      "INFO:scape:Successfully processed PMID 29691470\n",
      "INFO:scape:Successfully processed PMID 35358798\n",
      "INFO:scape:Successfully processed PMID 34713248\n",
      "INFO:scape:Successfully processed PMID 39962990\n",
      "INFO:scape:Successfully processed PMID 33371215\n",
      "INFO:scape:Successfully processed PMID 38310456\n",
      "INFO:scape:Successfully processed PMID 37545273\n",
      "INFO:scape:Successfully processed PMID 33213345\n",
      "INFO:scape:Successfully processed PMID 39459899\n",
      "INFO:scape:Successfully processed PMID 37451978\n",
      "INFO:scape:Successfully processed PMID 30194069\n",
      "INFO:scape:Successfully fetched details for 28 papers\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10477906/pdf\n",
      "INFO:scape:PDF saved to temp_37356052.pdf\n",
      "INFO:scape:Extracting text from temp_37356052.pdf\n",
      "INFO:scape:Successfully extracted text from temp_37356052.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8953071/pdf\n",
      "INFO:scape:PDF saved to temp_35337340.pdf\n",
      "INFO:scape:Extracting text from temp_35337340.pdf\n",
      "INFO:scape:Successfully extracted text from temp_35337340.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9787400/pdf\n",
      "INFO:scape:PDF saved to temp_36560658.pdf\n",
      "INFO:scape:Extracting text from temp_36560658.pdf\n",
      "INFO:scape:Successfully extracted text from temp_36560658.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7599677/pdf\n",
      "INFO:scape:PDF saved to temp_33003295.pdf\n",
      "INFO:scape:Extracting text from temp_33003295.pdf\n",
      "INFO:scape:Successfully extracted text from temp_33003295.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9065202/pdf\n",
      "INFO:scape:PDF saved to temp_35547744.pdf\n",
      "INFO:scape:Extracting text from temp_35547744.pdf\n",
      "INFO:scape:Successfully extracted text from temp_35547744.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3307543/pdf\n",
      "INFO:scape:PDF saved to temp_39292321.pdf\n",
      "INFO:scape:Extracting text from temp_39292321.pdf\n",
      "INFO:scape:Successfully extracted text from temp_39292321.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10693129/pdf\n",
      "INFO:scape:PDF saved to temp_38041049.pdf\n",
      "INFO:scape:Extracting text from temp_38041049.pdf\n",
      "INFO:scape:Successfully extracted text from temp_38041049.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9496048/pdf\n",
      "INFO:scape:PDF saved to temp_36139078.pdf\n",
      "INFO:scape:Extracting text from temp_36139078.pdf\n",
      "INFO:scape:Successfully extracted text from temp_36139078.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8525358/pdf\n",
      "INFO:scape:PDF saved to temp_34713248.pdf\n",
      "INFO:scape:Extracting text from temp_34713248.pdf\n",
      "INFO:scape:Successfully extracted text from temp_34713248.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7766694/pdf\n",
      "INFO:scape:PDF saved to temp_33371215.pdf\n",
      "INFO:scape:Extracting text from temp_33371215.pdf\n",
      "INFO:scape:Successfully extracted text from temp_33371215.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11512240/pdf\n",
      "INFO:scape:PDF saved to temp_39459899.pdf\n",
      "INFO:scape:Extracting text from temp_39459899.pdf\n",
      "INFO:scape:Successfully extracted text from temp_39459899.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10935483/pdf\n",
      "INFO:scape:PDF saved to temp_37451978.pdf\n",
      "INFO:scape:Extracting text from temp_37451978.pdf\n",
      "INFO:scape:Successfully extracted text from temp_37451978.pdf\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 12 papers\n",
      "\n",
      "Q: What are the main challenges in using CRISPR for cancer therapy?\n",
      "\n",
      "A: One of the main challenges in using CRISPR for cancer therapy is the potential for unintended consequences or off-target effects. This refers to the possibility that the CRISPR-Cas9 system could accidentally edit genes that are not intended to be modified. This can lead to unintended mutations or changes in gene expression that could have harmful effects on healthy cells.\n",
      "\n",
      "            Another challenge is the difficulty in precisely targeting cancer cells while avoiding healthy cells. This requires careful design of the CRISPR-Cas9 system to specifically recognize and bind to cancer cells, while leaving healthy cells unharmed.\n",
      "\n",
      "            Additionally, the CRISPR-Cas9 system may not be effective in all types of cancer cells. Some cancer cells may have genetic mutations that make them resistant to the CRISPR-Cas9 system, or may have mechanisms to repair any damage caused by the system.\n",
      "\n",
      "        Citations:\n",
      "\n",
      "        - Smith, S. D., & Liu, Y. (2017). CRISPR-Cas9 gene editing for cancer therapy. Nature Reviews Drug Discovery, 16(7), 457-465. https://\n",
      "\n",
      "Output token length: 256\n"
     ]
    }
   ],
   "source": [
    "# Initialize the assistant\n",
    "assistant = ResearchAssistantBM25()\n",
    "\n",
    "# Search for papers on a topic\n",
    "assistant.search_papers(\n",
    "    query=\"latest developments in CRISPR gene editing cancer therapy\",\n",
    "    max_results=20\n",
    ")\n",
    "\n",
    "# Ask questions\n",
    "questions = [\n",
    "    \"What are the main challenges in using CRISPR for cancer therapy?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    ans =assistant.answer_question(question)\n",
    "    print(f\"\\nA: {ans[0]}\")\n",
    "    print(f\"\\nOutput token length: {ans[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense embeddings (sentence-transformers/all-MiniLM-L6-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "class ResearchAssistant_sentrans:\n",
    "    def __init__(self):\n",
    "        # Initialize components for paper processing and analysis\n",
    "        self.scraper = PaperScraper()  # For retrieving papers from PubMed\n",
    "        self.embedding_model = embedding_model  # For generating text embeddings\n",
    "        self.tokenizer = tokenizer  # For tokenizing text for the LLM\n",
    "        self.model = model  # The language model for answering questions\n",
    "        self.paper_texts = []  # Store the full text of processed papers\n",
    "        self.paper_metadata = []  # Store metadata (title, authors, etc) for papers\n",
    "        \n",
    "        # Initialize ChromaDB client and collection\n",
    "        self.chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")  # Persist data\n",
    "        self.collection = self.chroma_client.get_or_create_collection(name=\"sentence_papers\")\n",
    "\n",
    "    def search_papers(self, query: str, max_results: int = 10):\n",
    "        \"\"\"Search and download papers for the given query\"\"\"\n",
    "        print(f\"Searching for papers about: {query}\")\n",
    "        \n",
    "        # Get paper IDs from PubMed search\n",
    "        pmids = self.scraper.search_pubmed(query, max_results)\n",
    "        # Fetch detailed information for each paper\n",
    "        papers = self.scraper.fetch_pubmed_details(pmids)\n",
    "        \n",
    "        # Process each paper found\n",
    "        for paper in papers:\n",
    "            if pdf_url := paper.get('full_text_link'):  # Check if full text PDF is available\n",
    "                try:\n",
    "                    # Download PDF to temporary file\n",
    "                    pdf_path = self.scraper.download_pdf(\n",
    "                        pdf_url, \n",
    "                        f\"temp_{paper['pubmed_id']}.pdf\"\n",
    "                    )\n",
    "                    # Extract plain text from PDF\n",
    "                    text = self.scraper.extract_text_from_pdf(pdf_path)\n",
    "                    \n",
    "                    # Save paper content and metadata\n",
    "                    self.paper_texts.append(text)\n",
    "                    self.paper_metadata.append(paper)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing paper {paper['pubmed_id']}: {e}\")\n",
    "                    \n",
    "        self._build_index()  # Create search index from processed papers\n",
    "        print(f\"Successfully processed {len(self.paper_texts)} papers\")\n",
    "\n",
    "    def _build_index(self):\n",
    "        \"\"\"Create ChromaDB index from paper embeddings\"\"\"\n",
    "        self.chunks = []\n",
    "        self.chunk_metadata = []\n",
    "\n",
    "        # Process each paper into chunks\n",
    "        for text, metadata in zip(self.paper_texts, self.paper_metadata):\n",
    "            # Split text into paragraphs\n",
    "            paragraphs = text.split('\\n\\n')\n",
    "            # Create overlapping chunks of 3 paragraphs\n",
    "            for i in range(0, len(paragraphs), 2):\n",
    "                chunk = ' '.join(paragraphs[i:i+2])\n",
    "                if len(chunk.split()) > 30:  # Only keep chunks with sufficient content\n",
    "                    self.chunks.append(chunk)\n",
    "                    self.chunk_metadata.append(metadata)\n",
    "\n",
    "        # Generate embeddings for all chunks\n",
    "        embeddings = self.embedding_model.encode(\n",
    "            self.chunks,\n",
    "            batch_size=4,  # Process 4 chunks at a time\n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True  # Convert to numpy for ChromaDB compatibility\n",
    "        )\n",
    "\n",
    "        # Store embeddings in ChromaDB\n",
    "        for i, (chunk, metadata, embedding) in enumerate(zip(self.chunks, self.chunk_metadata, embeddings)):\n",
    "            self.collection.add(\n",
    "                ids=[str(i)], \n",
    "                embeddings=[embedding.tolist()], \n",
    "                metadatas=[{\"title\": metadata[\"title\"], \"pubmed_id\": metadata[\"pubmed_id\"], \"chunk\": chunk}]\n",
    "            )\n",
    "\n",
    "    def answer_question(self, question: str, k: int = 5):\n",
    "        \"\"\"Answer a question using RAG\"\"\"\n",
    "        # Convert question to embedding vector\n",
    "        q_embedding = self.embedding_model.encode([question])[0]\n",
    "\n",
    "        # Find k most similar chunks using ChromaDB\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[q_embedding.tolist()],\n",
    "            n_results=k\n",
    "        )\n",
    "\n",
    "        # Build context from relevant chunks - LIMIT TOTAL LENGTH\n",
    "        context = \"\"\n",
    "        used_papers = set()\n",
    "        total_tokens = 0\n",
    "        max_tokens = 2048  # Set a reasonable limit for context length\n",
    "        \n",
    "        for result in results[\"metadatas\"][0]:\n",
    "            chunk = result[\"chunk\"]\n",
    "            paper_id = result[\"pubmed_id\"]\n",
    "\n",
    "            # Only include first chunk from each paper and check token length\n",
    "            if paper_id not in used_papers:\n",
    "                chunk_tokens = len(self.tokenizer.encode(chunk))\n",
    "                if total_tokens + chunk_tokens > max_tokens:\n",
    "                    break\n",
    "\n",
    "                used_papers.add(paper_id)\n",
    "                context += f\"\\nFrom paper '{result['title']}':\\n{chunk}\\n\"\n",
    "                total_tokens += chunk_tokens\n",
    "\n",
    "        # Construct shorter prompt\n",
    "        prompt = f\"\"\"Answer based on these excerpts. Include citations.\n",
    "\n",
    "        Excerpts: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer: \"\"\"\n",
    "\n",
    "        # Generate answer using LLM with controlled length\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=2048  # Hard limit on input length\n",
    "        ).to(\"cuda\")\n",
    "        \n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,  # Limit response length\n",
    "            temperature=0.7,  # Add some randomness to generation\n",
    "            num_return_sequences=1,  # Generate one response\n",
    "            do_sample=True,  # Use sampling instead of greedy decoding\n",
    "        )\n",
    "        input_length = inputs[\"input_ids\"].shape[1]  # Number of tokens in input prompt\n",
    "        output_token_length = outputs.shape[1] - input_length  # Total generated tokens excluding input\n",
    "\n",
    "        # Extract and clean up the generated answer\n",
    "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return answer.split(\"Answer: \")[-1].strip(), output_token_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the assistant\n",
    "assistant = ResearchAssistant_sentrans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scape:Searching PubMed for : latest developments in CRISPR gene editing cancer therapy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for papers about: latest developments in CRISPR gene editing cancer therapy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scape:Found 28 results\n",
      "INFO:scape:Fetching details for 28 papers...\n",
      "INFO:scape:Successfully processed PMID 37356052\n",
      "INFO:scape:Successfully processed PMID 36610813\n",
      "INFO:scape:Successfully processed PMID 36272261\n",
      "INFO:scape:Successfully processed PMID 35337340\n",
      "INFO:scape:Successfully processed PMID 39708520\n",
      "INFO:scape:Successfully processed PMID 38050977\n",
      "INFO:scape:Successfully processed PMID 34411650\n",
      "INFO:scape:Successfully processed PMID 31739699\n",
      "INFO:scape:Successfully processed PMID 36560658\n",
      "INFO:scape:Successfully processed PMID 33003295\n",
      "INFO:scape:Successfully processed PMID 39317648\n",
      "INFO:scape:Successfully processed PMID 35547744\n",
      "INFO:scape:Successfully processed PMID 39292321\n",
      "INFO:scape:Successfully processed PMID 35999480\n",
      "INFO:scape:Successfully processed PMID 32264803\n",
      "INFO:scape:Successfully processed PMID 38041049\n",
      "INFO:scape:Successfully processed PMID 36139078\n",
      "INFO:scape:Successfully processed PMID 29691470\n",
      "INFO:scape:Successfully processed PMID 35358798\n",
      "INFO:scape:Successfully processed PMID 34713248\n",
      "INFO:scape:Successfully processed PMID 39962990\n",
      "INFO:scape:Successfully processed PMID 33371215\n",
      "INFO:scape:Successfully processed PMID 38310456\n",
      "INFO:scape:Successfully processed PMID 37545273\n",
      "INFO:scape:Successfully processed PMID 33213345\n",
      "INFO:scape:Successfully processed PMID 39459899\n",
      "INFO:scape:Successfully processed PMID 37451978\n",
      "INFO:scape:Successfully processed PMID 30194069\n",
      "INFO:scape:Successfully fetched details for 28 papers\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10477906/pdf\n",
      "INFO:scape:PDF saved to temp_37356052.pdf\n",
      "INFO:scape:Extracting text from temp_37356052.pdf\n",
      "INFO:scape:Successfully extracted text from temp_37356052.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8953071/pdf\n",
      "INFO:scape:PDF saved to temp_35337340.pdf\n",
      "INFO:scape:Extracting text from temp_35337340.pdf\n",
      "INFO:scape:Successfully extracted text from temp_35337340.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9787400/pdf\n",
      "INFO:scape:PDF saved to temp_36560658.pdf\n",
      "INFO:scape:Extracting text from temp_36560658.pdf\n",
      "INFO:scape:Successfully extracted text from temp_36560658.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7599677/pdf\n",
      "INFO:scape:PDF saved to temp_33003295.pdf\n",
      "INFO:scape:Extracting text from temp_33003295.pdf\n",
      "INFO:scape:Successfully extracted text from temp_33003295.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9065202/pdf\n",
      "INFO:scape:PDF saved to temp_35547744.pdf\n",
      "INFO:scape:Extracting text from temp_35547744.pdf\n",
      "INFO:scape:Successfully extracted text from temp_35547744.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3307543/pdf\n",
      "INFO:scape:PDF saved to temp_39292321.pdf\n",
      "INFO:scape:Extracting text from temp_39292321.pdf\n",
      "INFO:scape:Successfully extracted text from temp_39292321.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10693129/pdf\n",
      "INFO:scape:PDF saved to temp_38041049.pdf\n",
      "INFO:scape:Extracting text from temp_38041049.pdf\n",
      "INFO:scape:Successfully extracted text from temp_38041049.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9496048/pdf\n",
      "INFO:scape:PDF saved to temp_36139078.pdf\n",
      "INFO:scape:Extracting text from temp_36139078.pdf\n",
      "INFO:scape:Successfully extracted text from temp_36139078.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8525358/pdf\n",
      "INFO:scape:PDF saved to temp_34713248.pdf\n",
      "INFO:scape:Extracting text from temp_34713248.pdf\n",
      "INFO:scape:Successfully extracted text from temp_34713248.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7766694/pdf\n",
      "INFO:scape:PDF saved to temp_33371215.pdf\n",
      "INFO:scape:Extracting text from temp_33371215.pdf\n",
      "INFO:scape:Successfully extracted text from temp_33371215.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11512240/pdf\n",
      "INFO:scape:PDF saved to temp_39459899.pdf\n",
      "INFO:scape:Extracting text from temp_39459899.pdf\n",
      "INFO:scape:Successfully extracted text from temp_39459899.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10935483/pdf\n",
      "INFO:scape:PDF saved to temp_37451978.pdf\n",
      "INFO:scape:Extracting text from temp_37451978.pdf\n",
      "INFO:scape:Successfully extracted text from temp_37451978.pdf\n",
      "Batches: 100%|██████████| 3/3 [00:00<00:00,  6.59it/s]\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 3\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 4\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 4\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 5\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 5\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 6\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 6\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 7\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 7\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 8\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 9\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 10\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 10\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 11\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 12 papers\n",
      "\n",
      "Q: What are the main challenges in using CRISPR for cancer therapy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 64.00it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A: CRISPR is a revolutionary gene editing technology that has shown promise in cancer therapy. However, there are still several challenges that need to be overcome before it can be widely used in clinical settings. \n",
      "\n",
      "        One of the main challenges is the safety of using CRISPR in humans. While CRISPR has shown to be effective in animal models, there is still a risk of unintended consequences when used in humans. For example, there is a possibility of off-target effects, where CRISPR edits genes other than the intended target, which could lead to unintended side effects. \n",
      "\n",
      "        Another challenge is the delivery of CRISPR to cancer cells. CRISPR requires specific conditions to be effective, and it may be difficult to deliver it to cancer cells in the body. Additionally, the body's immune system may recognize CRISPR as foreign and attack it, further complicating the delivery process. \n",
      "\n",
      "        Finally, there is a lack of understanding of how CRISPR works in cancer cells, which makes it difficult to develop personalized treatments. Each cancer cell is unique, and CRISPR may not work the same way in every cancer cell. Therefore, it is important to understand the biological\n",
      "\n",
      "Output token length: 256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Search for papers on a topic\n",
    "assistant.search_papers(\n",
    "    query=\"latest developments in CRISPR gene editing cancer therapy\",\n",
    "    max_results=20\n",
    ")\n",
    "\n",
    "# Ask questions\n",
    "questions = [\n",
    "    \"What are the main challenges in using CRISPR for cancer therapy?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    ans =assistant.answer_question(question)\n",
    "    print(f\"\\nA: {ans[0]}\")\n",
    "    print(f\"\\nOutput token length: {ans[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scape:Searching PubMed for : latest developments in CRISPR gene editing cancer therapy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for papers about: latest developments in CRISPR gene editing cancer therapy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:scape:Found 28 results\n",
      "INFO:scape:Fetching details for 28 papers...\n",
      "INFO:scape:Successfully processed PMID 37356052\n",
      "INFO:scape:Successfully processed PMID 36610813\n",
      "INFO:scape:Successfully processed PMID 36272261\n",
      "INFO:scape:Successfully processed PMID 35337340\n",
      "INFO:scape:Successfully processed PMID 39708520\n",
      "INFO:scape:Successfully processed PMID 38050977\n",
      "INFO:scape:Successfully processed PMID 34411650\n",
      "INFO:scape:Successfully processed PMID 31739699\n",
      "INFO:scape:Successfully processed PMID 36560658\n",
      "INFO:scape:Successfully processed PMID 33003295\n",
      "INFO:scape:Successfully processed PMID 39317648\n",
      "INFO:scape:Successfully processed PMID 35547744\n",
      "INFO:scape:Successfully processed PMID 39292321\n",
      "INFO:scape:Successfully processed PMID 35999480\n",
      "INFO:scape:Successfully processed PMID 32264803\n",
      "INFO:scape:Successfully processed PMID 38041049\n",
      "INFO:scape:Successfully processed PMID 36139078\n",
      "INFO:scape:Successfully processed PMID 29691470\n",
      "INFO:scape:Successfully processed PMID 35358798\n",
      "INFO:scape:Successfully processed PMID 34713248\n",
      "INFO:scape:Successfully processed PMID 39962990\n",
      "INFO:scape:Successfully processed PMID 33371215\n",
      "INFO:scape:Successfully processed PMID 38310456\n",
      "INFO:scape:Successfully processed PMID 37545273\n",
      "INFO:scape:Successfully processed PMID 33213345\n",
      "INFO:scape:Successfully processed PMID 39459899\n",
      "INFO:scape:Successfully processed PMID 37451978\n",
      "INFO:scape:Successfully processed PMID 30194069\n",
      "INFO:scape:Successfully fetched details for 28 papers\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10477906/pdf\n",
      "INFO:scape:PDF saved to temp_37356052.pdf\n",
      "INFO:scape:Extracting text from temp_37356052.pdf\n",
      "INFO:scape:Successfully extracted text from temp_37356052.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8953071/pdf\n",
      "INFO:scape:PDF saved to temp_35337340.pdf\n",
      "INFO:scape:Extracting text from temp_35337340.pdf\n",
      "INFO:scape:Successfully extracted text from temp_35337340.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9787400/pdf\n",
      "INFO:scape:PDF saved to temp_36560658.pdf\n",
      "INFO:scape:Extracting text from temp_36560658.pdf\n",
      "INFO:scape:Successfully extracted text from temp_36560658.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7599677/pdf\n",
      "INFO:scape:PDF saved to temp_33003295.pdf\n",
      "INFO:scape:Extracting text from temp_33003295.pdf\n",
      "INFO:scape:Successfully extracted text from temp_33003295.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9065202/pdf\n",
      "INFO:scape:PDF saved to temp_35547744.pdf\n",
      "INFO:scape:Extracting text from temp_35547744.pdf\n",
      "INFO:scape:Successfully extracted text from temp_35547744.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3307543/pdf\n",
      "INFO:scape:PDF saved to temp_39292321.pdf\n",
      "INFO:scape:Extracting text from temp_39292321.pdf\n",
      "INFO:scape:Successfully extracted text from temp_39292321.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10693129/pdf\n",
      "INFO:scape:PDF saved to temp_38041049.pdf\n",
      "INFO:scape:Extracting text from temp_38041049.pdf\n",
      "INFO:scape:Successfully extracted text from temp_38041049.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9496048/pdf\n",
      "INFO:scape:PDF saved to temp_36139078.pdf\n",
      "INFO:scape:Extracting text from temp_36139078.pdf\n",
      "INFO:scape:Successfully extracted text from temp_36139078.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8525358/pdf\n",
      "INFO:scape:PDF saved to temp_34713248.pdf\n",
      "INFO:scape:Extracting text from temp_34713248.pdf\n",
      "INFO:scape:Successfully extracted text from temp_34713248.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7766694/pdf\n",
      "INFO:scape:PDF saved to temp_33371215.pdf\n",
      "INFO:scape:Extracting text from temp_33371215.pdf\n",
      "INFO:scape:Successfully extracted text from temp_33371215.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11512240/pdf\n",
      "INFO:scape:PDF saved to temp_39459899.pdf\n",
      "INFO:scape:Extracting text from temp_39459899.pdf\n",
      "INFO:scape:Successfully extracted text from temp_39459899.pdf\n",
      "INFO:scape:Downloading PDF from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10935483/pdf\n",
      "INFO:scape:PDF saved to temp_37451978.pdf\n",
      "INFO:scape:Extracting text from temp_37451978.pdf\n",
      "INFO:scape:Successfully extracted text from temp_37451978.pdf\n",
      "Batches: 100%|██████████| 6/6 [00:01<00:00,  4.45it/s]\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 0\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 0\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 1\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 2\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 3\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 3\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 4\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 4\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 5\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 5\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 6\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 6\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 7\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 7\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 8\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 9\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 10\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 10\n",
      "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 11\n",
      "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Add of existing embedding ID: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 24 papers\n",
      "\n",
      "Q: What are the main challenges in using CRISPR for cancer therapy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 26.86it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A: One of the main challenges in using CRISPR for cancer therapy is off-target effects. CRISPR-Cas9 relies on the specificity of the guide RNA to bind to a particular target sequence in the genome. However, if the guide RNA is not designed perfectly, it can bind to unintended targets, causing unintended effects. This can lead to the activation of healthy cells or the suppression of cancer cells that are essential for the body's immune system to function properly (Fried et al., 2013).\n",
      "\n",
      "        Another challenge is the risk of generating mutations. CRISPR-Cas9 can introduce double-strand breaks in the genome, which can lead to the formation of mutations. While this can be beneficial in some cases, such as in the treatment of genetic diseases, it can also be harmful if it occurs in cancer cells (Rodriguez et al., 2015).\n",
      "\n",
      "        Additionally, the complexity of the human genome and the variability in the DNA sequences of cancer cells make it difficult to design guide RNAs that will be effective in all cases. This can lead to a lack of specificity and\n",
      "\n",
      "Output token length: 256\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Search for papers on a topic\n",
    "assistant.search_papers(\n",
    "    query=\"latest developments in CRISPR gene editing cancer therapy\",\n",
    "    max_results=20\n",
    ")\n",
    "\n",
    "# Ask questions\n",
    "questions = [\n",
    "    \"What are the main challenges in using CRISPR for cancer therapy?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    ans =assistant.answer_question(question)\n",
    "    print(f\"\\nA: {ans[0]}\")\n",
    "    print(f\"\\nOutput token length: {ans[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Assignment_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
